---
#title: "Atividade 3 - Parte de MLG - I"
#author: ""
#date: "XX/11/2021"
output: rmdformats::downcute
default_style: dark
# output: 
#   pdf_document:
#     fig_caption: yes
---

# Importando os dados

\quad Importando os pacotes necessários.

```{r warning=FALSE, message=F}
### Imagem
if(!require(ggplot2)){install.packages("ggplot2")}
library(ggplot2)
if(!require(ggpubr)){install.packages("ggpubr")}
library(ggpubr)
if(!require(qqplotr)){install.packages("qqplotr")}
library(qqplotr)
if(!require(RColorBrewer)){install.packages("RColorBrewer")}
library(RColorBrewer)
### Tratar
if(!require(tidyverse)){install.packages("tidyverse")}
library(tidyverse)
### Arvore
if(!require(rpart)){install.packages("rpart")}
library(rpart)
if(!require(partykit)){install.packages("partykit")}
library(partykit)
if(!require(ggparty)){install.packages("ggparty")}
library(ggparty)
### Arvore
if(!require(glmnet)){install.packages("glmnet")}
library(glmnet)
### XGBoost
if(!require(xgboost)){install.packages("xgboost")}
library(xgboost)
### KNN
if(!require(FNN)){install.packages("FNN")}
library(FNN)
### Naive Bayes
if(!require(naivebayes)){install.packages("naivebayes")}
library(naivebayes)

### Fazer a curva roc
if(!require(ROCR)){install.packages("ROCR")}
library(ROCR)
### Obter o ponto de corte otimo
if(!require(pROC)){install.packages("pROC")}
library(pROC)

```

\quad Em seguida, importa-se o banco de dados.
```{r warning=FALSE, message=F}
library(readr)
voice <- read_csv("D:/Mega/ufscar_mega/Ufscar/7° ENPE 3/MD/lista3/voice/voice.csv")


#=============================================
##### Faz o percentual do numero de NA
pMiss <- function(x){sum(is.na(x))/length(x)*100}
apply(voice,2,pMiss)
```

\quad Nenhuma observação ausente. Além disso, crias-se uma coluna de 1 e 0 com base no rótulo, pois alguns método exigem isso.

```{r}
### Se male --> 1, se female --> 0 
voice$label_numero <- ifelse(voice$label == "male", 1, 0)

table(voice$label)
```

\quad Além disso, nota-se que os dados são balanceados. 


## Treino e Teste

```{r warning=FALSE, message=F}
#=============================================
##### Data Split no voice
set.seed(37)
split = sample(c("Treino","Valida","Teste"),prob=c(0.6,0.2,0.2),
               size = nrow(voice),replace = T)

### Dividindo o variavel resposta]
voice_treino = voice[split == "Treino",]
voice_valida = voice[split == "Valida",]
voice_teste = voice[split == "Teste",]

split_treino_tudo = as.logical(c(c(split == "Treino") + 
                                   c(split == "Valida")))

voice_treino_tudo = voice[split_treino_tudo,]
```

## Árvore de classificação

```{r warning=FALSE, message=F}
arvore_class = rpart(label ~.,
                     method="class",
                     data=voice_treino_tudo[,-c(22)],
                     control=rpart.control(cp = 0.01))

melhorCp = 
  arvore_class$cptable[which.min(arvore_class$cptable[,"xerror"]),
                       "CP"]

melhorCp


```


```{r warning=FALSE, message=F,echo=F}
add_splitvar_breaks_index_new <- function(party_object, plot_data, round_digits = NULL) {
  
  plot_data$breaks_label <- I(rep(list(NA), length(party_object)))
  
  for (i in plot_data$id) {
    party_split <- party_object[[i]]$node$split
    party_node <- party_object[[i]]$node
    split_index <- party_split$index
    split_breaks <- party_split$breaks
    
    # check if node has a splitvar
    if (!is.null(party_split$varid)) {
      kids <- which(plot_data$parent == i)
      split_var <- names(party_object[[i]]$data)[party_split$varid]
      plot_data[i, "splitvar"] <- split_var
      
      # index
      # if only index provided, splitvar categorical. assign children according
      # to factor levels
      if (!is.null(split_index) & is.null(split_breaks)) {
        var_levels <- levels(party_object$data[,split_var])
        # iterate through index
        for (j in 1:length(split_index)) {
          if (is.na(split_index[j])) next
          # get kid index is pointing to
          kid <- kids[split_index[j]]
          # if first index  for kid, just assign according factor level
          if (is.na(plot_data$breaks_label[kid])) {
            plot_data[kid, "breaks_label"] <- var_levels[j]
            # else add factor level to present level(s)
          } else {
            plot_data[kid, "breaks_label"][[1]] <- list(c(plot_data[kid, "breaks_label"][[1]],
                                                          var_levels[j]))
          }
        }
      }
      
      # check whether intervals of continuous variable defined by breaks
      if (!is.null(split_breaks)) {
        # check if breaks are supposed to be rounded and apply if so
        if(!is.null(round_digits)) split_breaks <- round(split_breaks, round_digits)
        # if no index provided, intervals are supposed to be assigned
        # consecutively to kids. assign index accordingly.
        if (is.null(split_index)) split_index <- 1:(length(split_breaks) + 1)
        # iterate through index
        for (j in 1:length(split_index)) {
          kid <- kids[split_index[j]]
          # for first interval use -inf as lower bound
          if (j == 1) {
            # check whether more intervals lead to this kid. If so, don't use inequality signs
            if (split_index[j] %in% split_index[-j]) {
              split_interval <- paste0("(-Inf, ",
                                       split_breaks[j],
                                       ifelse(party_split$right == TRUE,
                                              "]",")"))
            } else {
              split_interval <- paste(ifelse(party_split$right == TRUE,
                                             "NA <= NA*","NA <  NA*"),
                                      #"\u2264","<"),
                                      split_breaks[1])
            }
            # for last interval use inf as upper bound
          } else if (j == length(split_index)) {
            # check whether more intervals lead to this kid. If so, don't use inequality signs
            if (split_index[j] %in% split_index[-j]) {
              split_interval <- paste0(ifelse(party_split$right == TRUE,
                                              "(","["),
                                       split_breaks[j - 1],
                                       ", Inf)")
            } else {
              split_interval <- paste(ifelse(party_split$right == TRUE,
                                             "NA >  NA*","NA >= NA*"),
                                      split_breaks[j - 1])
            }
            # else use break[j-1] for lower interval bound
          } else {
            split_interval <- paste0(ifelse(party_split$right == TRUE,
                                            "(","["),
                                     split_breaks[j - 1],", ",
                                     split_breaks[j],
                                     ifelse(party_split$right == TRUE,
                                            "]",")"))
          }
          
          if (is.na(plot_data$breaks_label[kid])) {
            plot_data[kid, "breaks_label"] <- split_interval
          }
          else {
            # plot_data[kid, "breaks_label"][[1]] <- list(c(plot_data[kid, "breaks_label"][[1]],
            #                                               split_interval))
            plot_data[kid, "breaks_label"][[1]] <- paste(plot_data[kid, "breaks_label"][[1]],
                                                         split_interval, sep = " | ")
          }
        }
        
      }
    }
  }
  return(plot_data["breaks_label"])
}


rounded_labels_cart <- 
  add_splitvar_breaks_index_new(party_object = as.party(arvore_class),
                                plot_data =ggparty:::get_plot_data(as.party(arvore_class)), 
                                round_digits = 3)


g1 = 
ggparty(as.party(arvore_class)) +
  geom_edge(size = 1) +
  
  geom_edge_label(size=3,
                  mapping = aes(label = unlist(rounded_labels_cart)),
                  data = rounded_labels_cart)+
  
  geom_node_info(aes(col = factor(level)))+
  
  geom_node_plot(gglist = 
                   list(geom_bar(aes(x = "", fill = label),
                                 position = position_fill()),
                        xlab(""),ylab("Percentual"),
                        theme_bw(base_size = 8),
                        theme(text = element_text(size = 14, 
                                                  family ="serif"),
                              legend.position = "none")),
                 shared_axis_labels = TRUE)+
  
  geom_node_label(aes(col = splitvar),
                  line_list = list(aes(label = paste("Nó", id)),
                                   aes(label = splitvar)),
                  # set graphical parameters for each line
                  line_gpar = list(list(size = 13, col = "black", fontface = "bold"),
                                   list(size = 12)),
                  ids = "inner") +
  
  geom_node_label(aes(label = paste0("Nó ", id,"\n(N = ",nodesize,")")),
                  fontface = "bold",
                  ids = "terminal",
                  size = 3,
                  nudge_y = -0.39,
                  nudge_x = 0.026)+
  
  theme(legend.position = "none",
        panel.background = element_rect(fill = 'white', colour = 'white'))+
  scale_color_brewer(palette="Dark2")


g1
ggarrange(g1)
```

\quad Obtendo os valores preditos para a árvore de decisão sem poda.

```{r warning=FALSE, message=F}
### estou pegando a segunda coluna de pred_arvore,
## pois quero o male, uma vez que male-->1.
predito_arvore = predict(arvore_class,
                      newdata = voice_teste[,-c(21,22)],
                      type=c("prob"))[,2]


predito_c_arvore = predict(arvore_class,
                      newdata = voice_teste[,-c(21,22)],
                      type="class")

```

## Arvore Com Poda

```{r warning=FALSE, message=F,echo=F}
rounded_labels_cart_poda <- 
  add_splitvar_breaks_index_new(party_object = as.party(prune(arvore_class,cp=melhorCp)),
                                plot_data =ggparty:::get_plot_data(as.party(prune(arvore_class,cp=melhorCp))), 
                                round_digits = 3)


g2 = 
ggparty(as.party(prune(arvore_class,cp=melhorCp))) +
  geom_edge(size = 1) +
  
  geom_edge_label(size=3,
                  mapping = aes(label = unlist(rounded_labels_cart_poda)),
                  data = rounded_labels_cart_poda)+
  
  geom_node_info(aes(col = factor(level)))+
  
  geom_node_plot(gglist = 
                   list(geom_bar(aes(x = "", fill = label),
                                 position = position_fill()),
                        xlab(""),ylab("Percentual"),
                        theme_bw(base_size = 8),
                        theme(text = element_text(size = 14, 
                                                  family ="serif"),
                              legend.position = "none")),
                 shared_axis_labels = TRUE)+
  
  geom_node_label(aes(col = splitvar),
                  line_list = list(aes(label = paste("Nó", id)),
                                   aes(label = splitvar)),
                  # set graphical parameters for each line
                  line_gpar = list(list(size = 13, col = "black", fontface = "bold"),
                                   list(size = 12)),
                  ids = "inner") +
  
  geom_node_label(aes(label = paste0("Nó ", id,"\n(N = ",nodesize,")")),
                  fontface = "bold",
                  ids = "terminal",
                  size = 3,
                  nudge_y = -0.66,
                  nudge_x = 0.026)+
  
  theme(legend.position = "none",
        panel.background = element_rect(fill = 'white', colour = 'white'))+
  scale_color_brewer(palette="Dark2")


g2
ggarrange(g2)
```

\quad Após a poda, a árvore ficou bem menor, possuindo apenas dois nós filhos. Em seguida, obtém-se os valores preditos para a árvore de decisão com poda.

```{r warning=FALSE, message=F}
### estou pegando a segunda coluna de pred_arvore,
## pois quero o male, uma vez que male-->1.
predito_arvore_poda = predict(prune(arvore_class,cp=melhorCp),
                      newdata = voice_teste[,-c(21,22)],
                      type=c("prob"))[,2]

predito_c_arvore_poda = predict(prune(arvore_class,cp=melhorCp),
                      newdata = voice_teste[,-c(21,22)],
                      type=c("class"))

```




## Regressão Logística (sem Lasso)

```{r}
modelo_reg_logis <- 
  glmnet(x = voice_treino_tudo[,-c(21,22)], 
         y = voice_treino_tudo$label_numero, 
         alpha = 0, lambda = 0,
         family = "binomial",
         stantardize = T)
```


```{r echo = FALSE, message=FALSE,warning=FALSE,fig.cap="Coeficientes na Regressão logis"}
#=============================================
##### Grafico dos Coef do Easy
coefs_logis = 
  data.frame(Palavra=names(coef(modelo_reg_logis)[,1]),
             Coeficientes=coef(modelo_reg_logis)[,1])
  
coefs_pos_logis = coefs_logis %>%
  arrange(desc(Coeficientes))

coefs_neg_logis = coefs_logis %>%
  arrange(Coeficientes)

#sum(coefs_pos_logis[,2] > 0)
#sum(coefs_neg_logis[,2] < 0)

graf_pos_logis = 
  ggplot(data=coefs_pos_logis[2:sum(coefs_pos_logis[,2]>0),],
         aes(x=reorder(Palavra,Coeficientes),
             y=Coeficientes,
             fill=reorder(Palavra,Coeficientes)))+
  geom_bar(stat="identity",col="white")+
  scale_y_continuous(breaks = scales::pretty_breaks(n=7))+
  coord_flip()+
  scale_fill_manual(values=colorRampPalette(brewer.pal(3,"Reds"))(sum(coefs_pos_logis[,2]>0)-1) )+
  theme_bw()+
  theme(text = element_text(size = 14, 
                            family ="serif"),
        plot.title = element_text(hjust = 0.5),
        legend.position = "none",
        axis.text.y = element_text(face="bold", color="black", 
                                   size=15))+
  labs(title = "Positivos", 
       x = "", y = "")

#graf_pos_logis  

graf_neg_logis = 
  ggplot(data=coefs_neg_logis[1:sum(coefs_neg_logis[,2]<0),],
         aes(x=reorder(Palavra,-Coeficientes),
             y=Coeficientes,
             fill=reorder(Palavra,-Coeficientes)))+
  geom_bar(stat="identity",col="white")+
  scale_y_continuous(breaks = scales::pretty_breaks(n=7))+
  coord_flip()+
  scale_fill_manual(values=colorRampPalette(brewer.pal(3,"Blues"))(sum(coefs_neg_logis[,2]>0)))+
  theme_bw()+
  theme(text = element_text(size = 14, 
                            family ="serif"),
        plot.title = element_text(hjust = 0.5),
        legend.position = "none",
        axis.text.y = element_text(face="bold", color="black", 
                                   size=15))+
  labs(title = "Negativos", 
       x = "Estimativa\n", y = "")

#graf_neg_logis

graf_logis_coef = 
ggarrange(graf_neg_logis,graf_pos_logis,
          labels = c("A","B"))

graf_logis_coef
```


```{r warning=FALSE, message=F}
### male-->1.
predito_reg = predict(modelo_reg_logis,
                   newx = as.matrix(voice_teste[,-c(21,22)]),
                   type = "response")

predito_c_reg = factor(ifelse(predito_reg>0.5,
                              "male","female"))
```


## Regressão Logística (Lasso)

```{r message=FALSE,warning=FALSE}
cv_lasso <- 
  cv.glmnet(x=as.matrix(voice_treino_tudo[,-c(21,22)]),
            y=voice_treino_tudo$label_numero, 
            alpha = 1,nfolds = 10,
            family="binomial",
            stantardize = F)

plot(cv_lasso)

modelo_reg_lasso = 
  glmnet(x=as.matrix(voice_treino_tudo[,-c(21,22)]), 
         y=voice_treino_tudo$label_numero,
         family="binomial",
         alpha=1,
         lambda = cv_lasso$lambda.min,
         stantardize = T)
```



```{r echo = FALSE, message=FALSE,warning=FALSE}
coefs_lasso = 
  data.frame(Palavra=names(coef(modelo_reg_lasso)[,1]),
             Coeficientes=coef(modelo_reg_lasso)[,1])

coefs_lasso = coefs_lasso %>%
  filter(Coeficientes != 0)

coefs_pos_lasso = coefs_lasso %>%
  arrange(desc(Coeficientes))

coefs_neg_lasso = coefs_lasso %>%
  arrange(Coeficientes)

#sum(coefs_pos_lasso[,2] > 0)
#sum(coefs_neg_lasso[,2] < 0)

graf_pos_lasso = 
  ggplot(data=coefs_pos_lasso[2:sum(coefs_pos_lasso[,2]>0),],
         aes(x=reorder(Palavra,Coeficientes),
             y=Coeficientes,
             fill=reorder(Palavra,Coeficientes)))+
  geom_bar(stat="identity",col="white")+
  scale_y_continuous(breaks = scales::pretty_breaks(n=7))+
  coord_flip()+
  scale_fill_manual(values=colorRampPalette(brewer.pal(3,"Reds"))(sum(coefs_pos_lasso[,2]>0)-1) )+
  theme_bw()+
  theme(text = element_text(size = 14, 
                            family ="serif"),
        plot.title = element_text(hjust = 0.5),
        legend.position = "none",
        axis.text.y = element_text(face="bold", color="black", 
                                   size=15))+
  labs(title = "Positivos", 
       x = "", y = "")

#graf_pos_lasso  

graf_neg_lasso = 
  ggplot(data=coefs_neg_lasso[1:sum(coefs_pos_lasso[,2]>0),],
         aes(x=reorder(Palavra,-Coeficientes),
             y=Coeficientes,
             fill=reorder(Palavra,-Coeficientes)))+
  geom_bar(stat="identity",col="white")+
  scale_y_continuous(breaks = scales::pretty_breaks(n=7))+
  coord_flip()+
  scale_fill_manual(values=colorRampPalette(brewer.pal(3,"Blues"))(sum(coefs_pos_lasso[,2]>0)))+
  theme_bw()+
  theme(text = element_text(size = 14, 
                            family ="serif"),
        plot.title = element_text(hjust = 0.5),
        legend.position = "none",
        axis.text.y = element_text(face="bold", color="black", 
                                   size=15))+
  labs(title = "Negativos", 
       x = "Estimativa\n", y = "")

#graf_neg_lasso

graf_lasso_coef =
ggarrange(graf_neg_lasso,graf_pos_lasso,
          labels = c("A","B"))
graf_lasso_coef
```

```{r warning=FALSE, message=F}
### male-->1.
predito_reg_lasso = predict(modelo_reg_lasso,
                   newx = as.matrix(voice_teste[,-c(21,22)]),
                   type = "response")

predito_c_reg_lasso = factor(ifelse(predito_reg_lasso>0.5,
                              "male","female"))
```


## Naive Bayes

```{r, message=F,warning=F}
mod_naive_bayes = 
  naive_bayes(x=voice_treino_tudo[,-c(21,22)],
              y=voice_treino_tudo$label)
```


```{r, message=F,warning=F}
### estou pegando a segunda coluna de pred_arvore,
## pois quero o male, uma vez que male-->1.

predito_naive_bayes = 
  predict(mod_naive_bayes,
          newdata = voice_teste[,-c(21,22)],
          type="prob")[,2]

predito_c_naive_bayes =
  predict(mod_naive_bayes,
          newdata = voice_teste[,-c(21,22)],
          type="class")
```


## KNN

```{r}
media_treino = data.frame(voice_treino[,-c(21,22)]) %>%
  summarise_all("mean")

sd_treino = data.frame(voice_treino[,-c(21,22)]) %>%
  summarise_all("sd")

#=============================================
##### Fazendo o laco do KNN com o conjunto
#### de validacao

k.grid = round(seq(1,100,length.out=50))
erro = rep(NA,length(k.grid))
start_time <- Sys.time()
for(ii in seq_along(k.grid)){
  
  predito = 
    knn(train=scale(voice_treino[,-c(21,22)]),
        test =scale(voice_valida[,-c(21,22)],
                   center=media_treino,
                   scale=sd_treino),
        cl=voice_treino$label,
        k=k.grid[ii])
  
  erro[ii] = mean(predito != voice_valida$label)
}
end_time <- Sys.time()
end_time - start_time
### Melhor k
k.grid[which.min(erro)]
```

```{r echo = FALSE, message=FALSE,warning=FALSE}
ggplot(data=data.frame(k.grid,erro),
       aes(x=k.grid, y=erro)) +
  geom_line(color="grey",size=2) +
  geom_point(shape=21, color="black", fill="#69b3a2", size=3)  +
  theme_bw()+
  theme(text = element_text(size = 14, 
                            family ="serif"),
        plot.title = element_text(hjust = 0.5),
        legend.position = "none")+
  labs(title = "Valores de K no KNN", 
       x = "K", y = "Acurácia")
```

Escolhido o k, basta calcular o risco e seu intervalo na amostra de teste.
```{r message=F,warning=F}
#=============================================
##### Fazendo o KNN na amostra Teste
##### Lembrando que o predito jah eh 
#### o classficacao, e nao a probabilidade.
predito_c_knn =
  knn(train=scale(voice_treino_tudo[,-c(21,22)]),
      test =scale(voice_teste[,-c(21,22)],
                  center=media_treino,
                  scale=sd_treino),
        cl=voice_treino_tudo$label,
        k=k.grid[which.min(erro)])
```

## XGBoost

```{r}
#=============================================
##### Mat do XGBoost

xgb_mat_treino_tudo = 
  xgb.DMatrix(as.matrix(voice_treino_tudo[,-c(21,22)]),
              label = voice_treino_tudo$label_numero)
  
xgb_mat_teste = 
  xgb.DMatrix(as.matrix(voice_teste[,-c(21,22)]),
              label = voice_teste$label_numero)

#=============================================
##### CV do xgb para escolher a iteracao

cv_xgb <- xgb.cv(data = xgb_mat_treino_tudo,
                 nrounds = 1000,
                 nfold = 10,
                 early_stopping_rounds = 30,
                 prediction = TRUE,
                 metric = "auc",
                 verbose = 0,
                 objective = "binary:logistic")

### Melhor iteracao
cv_xgb$evaluation_log[cv_xgb$best_iteration,]
```

```{r echo = FALSE, message=FALSE,warning=FALSE,fig.cap="Early Stop no XGB"}
xgb_dados_serie = 
  data.frame(cv_xgb$evaluation_log$iter,
                         cv_xgb$evaluation_log$test_auc_mean,
                         cv_xgb$evaluation_log$train_auc_mean)

names(xgb_dados_serie) =
  c("Iteracao","Media_RMSE_Valida","Media_RMSE_Treino")

graf_xgb_serie_RMSE =
  ggplot(data = xgb_dados_serie)+
  
  geom_line(aes(x = Iteracao, 
                y = Media_RMSE_Valida,
                color = "1"),
            size = 0.8)+
  
  geom_line(aes(x = Iteracao, 
                y = Media_RMSE_Treino,
                color = "2"),
            size = 0.8)+
  
  scale_x_continuous(breaks = scales::pretty_breaks(n = 10))+
  
  scale_y_continuous(breaks = scales::pretty_breaks(n = 10)) +
  
  theme_bw()+
  
  theme(plot.title = element_text(hjust = 0.5),
        text = element_text(size = 14, 
                            family ="serif"),
        legend.key = element_rect(colour = "white", 
                                  fill = "white"))+
  
  scale_color_manual(name = "",
                     values = c("red",
                                "steelblue"),
                     labels = c("Validações",
                                "Treinos"))+
  
  labs(y = "AUC",
       x = "Iterações",
       title = "Média das AUCs dos 10 folders")


graf_xgb_serie_RMSE
```

```{r message=FALSE,warning=FALSE}
#=============================================
##### Fazendo o XBG
modelo_xgb = 
  xgboost(data = xgb_mat_treino_tudo,
      nrounds = cv_xgb$best_iteration,
      eval_metric = "auc",
      verbose = 0,
      objective = "binary:logistic")
```

```{r echo = FALSE, message=FALSE,warning=FALSE}
xgb_dados_importancia = 
  xgb.importance(model = modelo_xgb) %>% 
  mutate(rank = dense_rank(desc(Gain)))

ggplot(data=xgb_dados_importancia[which(xgb_dados_importancia$rank <= 13),], 
       aes(x = reorder(Feature, +Gain), 
           y = Gain,
           fill = reorder(Feature, -Gain))) +
  scale_y_continuous(breaks = scales::pretty_breaks(n=10))+
  geom_bar(stat="identity",width=0.6) +
  coord_flip(clip = "off")+
  theme_bw()+
  theme(text = element_text(size = 14, 
                            family ="serif"),
        plot.title = element_text(hjust = 0.5),
        legend.position = "none")+
  theme(axis.text.y = element_text(face="bold", color="black", 
                                   size=15)) +
  labs(title = "XG Boost - Importância", 
       x = "", y = "Importância")
```


\quad O mesmo que ocorre na árvore decisão, em que o **meanfun** foi a covariável mais importante.


```{r message=FALSE,warning=FALSE}
predito_xgb <- predict(modelo_xgb, xgb_mat_teste,
                       type="prob")

predito_c_xgb = factor(ifelse(predito_xgb >0.5,
                       "male","female"))
```

# Riscos a um corte 0.5

\quad Considera-se que se a probabilidade for maior que $0.5$, então a observação predita é **male**, se não, é **female**.

```{r message=F,warning=F,echo=F}
riscos = list()

riscos$arvore_05 = mean(voice_teste$label!=predito_c_arvore)
riscos$arvore_poda_05 = mean(voice_teste$label!=predito_c_arvore_poda)

riscos$reg_log_05 = mean(voice_teste$label!=predito_c_reg)
riscos$reg_log_lasso_05 = 
  mean(voice_teste$label!=predito_c_reg_lasso)

riscos$naive_05 = mean(voice_teste$label!=predito_c_naive_bayes)

riscos$knn_05 = mean(voice_teste$label!=predito_c_knn)

riscos$xgb_05 = mean(voice_teste$label!=predito_c_xgb)

riscos
```

\quad XGB foi o melhor.

\quad Em seguida, se faz as tabelas de confusão (corte de 0.5 para male), lembrando que nas linhas são os valores preditos e nas colunas, os originais.

```{r message=F,warning=F,echo=F}
table(predito_c_arvore,voice_teste$label)
table(predito_c_arvore_poda,voice_teste$label)

table(predito_c_reg,voice_teste$label)
table(predito_c_reg_lasso,voice_teste$label)

table(predito_c_naive_bayes,voice_teste$label)

table(predito_c_knn,voice_teste$label)

table(predito_c_xgb,voice_teste$label)
```


# Curvas ROC

\quad Para fazer as curvas ROC, considera-se os métodos probabilísticos, que são todos, exceto KNN e árvores. Mas mesmo que a árvore não seja, pode-se fazer pra ela usando a proporção das classes nos nós finais.
```{r}
#=====================
# Pegando os valores

pred_roc1 <- prediction(predito_arvore,voice_teste$label_numero)
perf1 <- performance(pred_roc1,"tpr","fpr")

pred_roc2 <- prediction(predito_arvore_poda,voice_teste$label_numero)
perf2 <- performance(pred_roc2,"tpr","fpr")

pred_roc3 <- prediction(predito_reg,voice_teste$label_numero)
perf3 <- performance(pred_roc3,"tpr","fpr")


pred_roc4 <- prediction(predito_reg_lasso,voice_teste$label_numero)
perf4 <- performance(pred_roc4,"tpr","fpr")

pred_roc5 <- prediction(predito_naive_bayes,voice_teste$label_numero)
perf5 <- performance(pred_roc5,"tpr","fpr")

pred_roc6 <- prediction(predito_xgb,voice_teste$label_numero)
perf6 <- performance(pred_roc6,"tpr","fpr")


#=====================
# Pegando os valores

vetor_de_espec =
  c(as.vector(perf1@x.values)[[1]],
    as.vector(perf2@x.values)[[1]],
    as.vector(perf3@x.values)[[1]],
    as.vector(perf4@x.values)[[1]],
    as.vector(perf5@x.values)[[1]],
    as.vector(perf6@x.values)[[1]])

vetor_de_sensi =
  c(as.vector(perf1@y.values)[[1]],
    as.vector(perf2@y.values)[[1]],
    as.vector(perf3@y.values)[[1]],
    as.vector(perf4@y.values)[[1]],
    as.vector(perf5@y.values)[[1]],
    as.vector(perf6@y.values)[[1]])

qual_mod = factor(c(rep(1, length(as.vector(perf1@y.values)[[1]]) ),
                  rep(2, length(as.vector(perf2@y.values)[[1]]) ),
                  rep(3, length(as.vector(perf3@y.values)[[1]]) ),
                  rep(4, length(as.vector(perf4@y.values)[[1]]) ),
                  rep(5, length(as.vector(perf5@y.values)[[1]]) ),
                  rep(6, length(as.vector(perf6@y.values)[[1]]) )))

dados_para_rocs = data.frame(vetor_de_espec,
                             vetor_de_sensi,
                             qual_mod)

graf_rocs = 
  ggplot(data = dados_para_rocs) + 
  geom_line(aes(x = vetor_de_espec, y = vetor_de_sensi, 
                color = qual_mod),
            size = 1)+
  
  scale_x_continuous(breaks = scales::pretty_breaks(n = 7))+
  
  scale_y_continuous(breaks = scales::pretty_breaks(n = 7)) +
  
  theme_bw()+
  
  theme(text = element_text(size = 14, 
                            family ="serif"),
        plot.title = element_text(hjust = 0.5))+
  
  scale_color_brewer(name = "Modelos\n",
                     palette="Dark2",
                     labels = c("Árvore",
                                "Árvore com Poda",
                                "Reg. Logística",
                                "Reg. Logística com lasso",
                                "Naive Bayes",
                                "XGBoost"))+
  labs(y = "Sensibilidade",
       x = "1 - Especificidade",
       title = "Curva ROC para diferentes modelos")+
  guides(linetype = "none")

graf_rocs

graf_rocs_zoom = 
  graf_rocs + 
  labs(title = "Curva ROC para diferentes modelos com zoom") +
  coord_cartesian(ylim=c(0.8,1))

graf_rocs_zoom
```

\quad Além disso, uma forma de comparar todos esses modelos que retorna probabilidades, é com o uso da árvore abaixo da curva ROC.

```{r, echo=F,message=F,warning=F}
#=========================================
#===== Area abaixo da curva
#=========================================

cat('Area da árvore:',
    as.numeric(performance(pred_roc1,"auc")@y.values),
    '\n',
    'Area da árvore com poda:',
    as.numeric(performance(pred_roc2,"auc")@y.values),
    '\n',
    'Area da regresão logística:',
    as.numeric(performance(pred_roc3,"auc")@y.values),
    '\n',
    'Area da regressão logística com lasso:',
    as.numeric(performance(pred_roc4,"auc")@y.values),
    '\n',
    'Area do Naive Bayes:',
    as.numeric(performance(pred_roc5,"auc")@y.values),
    '\n',
    'Area do XGboost:',
    as.numeric(performance(pred_roc6,"auc")@y.values),
    '\n')
```

```{r echo=F,message=F,warning=F}
#=========================================
#===== Encontrndo o ponto de corte otimo
#=========================================

p1 = coords(roc(as.vector(voice_teste$label_numero),predito_arvore), 
            "best", "threshold",transpose = T)[[1]]

p2 = coords(roc(as.vector(voice_teste$label_numero),predito_arvore_poda), 
            "best", "threshold",transpose = T)[[1]]

p3 = coords(roc(as.vector(voice_teste$label_numero),as.vector(predito_reg)), 
            "best", "threshold",transpose = T)[[1]]

p4 = coords(roc(as.vector(voice_teste$label_numero),as.vector(predito_reg_lasso)), 
            "best", "threshold",transpose = T)[[1]]

p5 = coords(roc(as.vector(voice_teste$label_numero),predito_naive_bayes), 
            "best", "threshold",transpose = T)[[1]]

p6 = coords(roc(as.vector(voice_teste$label_numero),predito_xgb), 
            "best", "threshold",transpose = T)[[1]]

cat('Ponto de corte da árvore:',p1,
    '\n',
    'Ponto de corte da árvore com poda:',p2,
    '\n',
    'Ponto de corte da regresão logística:',p3,
    '\n',
    'Ponto de corte da regressão logística com lasso:',p4,
    '\n',
    'Ponto de corte do Naive Bayes:',p5,
    '\n',
    'Ponto de corte do XGboost:',p6,
    '\n')
```

\quad Nota-se o elevado ponto de corte da árvore sem poda, das regressões e do XGB, justo métodos que obtiveram boas áreas abaixo da curva.

\quad Dado esses pontos de corte, se faz a matriz de confusão para cada método, na ordem:\

* Árvore;\
* Árvore com Poda;\
* Reg. Logística;\
* Reg. Logística com lasso;\
* Naive Bayes;\
* XGBoost;\

```{r echo=F,message=F,warning=F}
#=========================================
#===== Usando o ponto de corte otimo
#=========================================

corte1 <- ifelse(predito_arvore > p1, 
                'Male', 
                'Female')

tabela1 <- table(corte1,as.vector(voice_teste$label_numero))
colnames(tabela1)<- c("Female","Male")
tabela1

#===========================================

corte2 <- ifelse(predito_arvore_poda > p2, 
                 'Male', 
                 'Female')

tabela2 <- table(corte2,as.vector(voice_teste$label_numero))
colnames(tabela2)<- c("Female","Male")
tabela2

#===========================================
corte3 <- ifelse(predito_reg > p3, 
                 'Male', 
                 'Female')

tabela3 <- table(corte3,as.vector(voice_teste$label_numero))
colnames(tabela3)<- c("Female","Male")
tabela3


#===========================================
corte4 <- ifelse(predito_reg_lasso > p4, 
                 'Male', 
                 'Female')

tabela4 <- table(corte4,as.vector(voice_teste$label_numero))
colnames(tabela4)<- c("Female","Male")
tabela4
#===========================================
corte5 <- ifelse(predito_naive_bayes > p5, 
                 'Male', 
                 'Female')

tabela5 <- table(corte5,as.vector(voice_teste$label_numero))
colnames(tabela5)<- c("Female","Male")
tabela5

#===========================================
corte6 <- ifelse(predito_xgb > p6, 
                 'Male', 
                 'Female')

tabela6 <- table(corte6,as.vector(voice_teste$label_numero))
colnames(tabela6)<- c("Female","Male")
tabela6

```
